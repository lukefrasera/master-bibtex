@inproceedings{Baak2011,
abstract = {In recent years, depth cameras have become a widely available sensor type that captures depth images at real-time frame rates. Even though recent approaches have shown that 3D pose estimation from monocular 2.5D depth images has become feasible, there are still challenging problems due to strong noise in the depth data and self-occlusions in the motions being captured. In this paper, we present an efficient and robust pose estimation framework for tracking full-body motions from a single depth image stream. Following a data-driven hybrid strategy that combines local optimization with global retrieval techniques, we contribute several technical improvements that lead to speed-ups of an order of magnitude compared to previous approaches. In particular, we introduce a variant of Dijkstra's algorithm to efficiently extract pose features from the depth data and describe a novel late-fusion scheme based on an efficiently computable sparse Hausdorff distance to combine local and global pose estimates. Our experiments show that the combination of these techniques facilitates real-time tracking with stable results even for fast and complex motions, making it applicable to a wide range of inter-active scenarios.},
author = {Baak, Andreas and Muller, Meinard and Bharaj, Gaurav and Seidel, Hans-Peter and Theobalt, Christian},
booktitle = {2011 International Conference on Computer Vision},
doi = {10.1109/ICCV.2011.6126356},
isbn = {978-1-4577-1102-2},
issn = {1550-5499},
keywords = {3D pose estimation,Cameras,Databases,Dijkstra's algorithm,Estimation,Joints,Optimization,Torso,Tracking,cameras,data-driven approach,data-driven hybrid strategy,depth camera,depth data,full-body motion tracking,global pose estimates,global retrieval techniques,image motion analysis,image reconstruction,local pose estimates,monocular 2.5D depth images,object tracking,pose estimation,pose features,real-time frame rates,real-time full body pose reconstruction,real-time tracking,self-occlusions,single depth image stream,sparse Hausdorff distance},
language = {English},
month = nov,
pages = {1092--1099},
publisher = {IEEE},
title = {{A data-driven approach for real-time full body pose reconstruction from a depth camera}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6126356},
year = {2011}
}
@article{BarryBrianWerger,
author = {{Barry Brian Werger}, Maja J. Mataric},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barry Brian Werger - Unknown - Broadcast of Local Eligibility for Multi-Target Observation.pdf:pdf},
pages = {347----356},
title = {{Broadcast of Local Eligibility for Multi-Target Observation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.996}
}
@article{Bicho2011,
abstract = {In this chapter we present results of our ongoing research on efficient and fluent human-robot collaboration that is heavily inspired by recent experimental findings about the neurocognitive mechanisms supporting joint action in humans. The robot control architecture implements the joint coordination of actions and goals as a dynamic process that integrates contextual cues, shared task knowledge and the predicted outcome of the user’s motor behavior. The architecture is formalized as a coupled system of dynamic neural fields representing a distributed network of local but connected neural populations with specific functionalities. We validate the approach in a task in which a robot and a human user jointly construct a toy ‘vehicle’. We show that the context-dependent mapping from action observation onto appropriate complementary actions allows the robot to cope with dynamically changing joint action situations. More specifically, the results illustrate crucial cognitive capacities for efficient and successful human-robot collaboration such as goal inference, error detection and anticipatory action selection.},
author = {Bicho, Estela and Erlhagen, Wolfram and Louro, Lu\'{\i}s and {Costa e Silva}, Eliana and Silva, Rui and Hip\'{o}lito, Nzoji},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bicho et al. - 2011 - A dynamic field approach to goal inference, error detection and anticipatory action selection in human-robot colla.pdf:pdf},
isbn = {978-9027204554},
journal = {New Frontiers in Human-Robot Interaction (Advances in Interaction Studies)},
keywords = {Action selection,Anticipation,Dynamic Fields,Error detection,Goal inference,Human-robot collaboration,Human-robot interaction},
pages = {135--164},
title = {{A dynamic field approach to goal inference, error detection and anticipatory action selection in human-robot collaboration}},
url = {http://benjamins.com/\#catalog/books/ais.2.10bic/details$\backslash$nhttp://hdl.handle.net/1822/17339},
year = {2011}
}
@inproceedings{Bleiweiss2009,
address = {New York, New York, USA},
author = {Bleiweiss, Amit and Kutliroff, Eran Eilat Gershom},
booktitle = {ACM SIGGRAPH ASIA 2009 Sketches on - SIGGRAPH ASIA '09},
doi = {10.1145/1667146.1667172},
month = dec,
pages = {1},
publisher = {ACM Press},
title = {{Markerless motion capture using a single depth sensor}},
url = {http://dl.acm.org/citation.cfm?id=1667146.1667172},
year = {2009}
}
@article{Breazeal2004,
abstract = {This paper explores the topic of human-robot interaction (HRI) from the perspective of designing sociable autonomous robots-robots designed to interact with people in a human-like way. There are a growing number of applications for robots that people can engage as capable creatures or as partners rather than tools, yet little is understood about how to best design robots that interact with people in this way. The related field of human-computer interaction (HCI) offers important insights, however autonomous robots are a very different technology from desktop computers. In this paper, we look at the field of HRI from an HCI perspective, pointing out important similarities yet significant differences that may ultimately make HRI a distinct area of inquiry. One outcome of this discussion is that it is important to view the design and evaluation problem from the robot's perspective as well as that of the human. Taken as a whole, this paper provides a framework with which to design and evaluate sociable robots from a HRI perspective.},
author = {Breazeal, C.},
doi = {10.1109/TSMCC.2004.826268},
issn = {1094-6977},
journal = {IEEE Transactions on Systems, Man and Cybernetics, Part C (Applications and Reviews)},
keywords = {Application software,HCI,HRI,Human computer interaction,Human robot interaction,Humanoid robots,Orbital robotics,Petroleum,Planets,Positron emission tomography,Senior citizens,Service robots,autonomous robots design,desktop computer,human computer interaction,human-computer interaction,human-robot interaction,learning (artificial intelligence),microcomputers,robot view,robots,social robot partner,socially guided learning},
month = may,
number = {2},
pages = {181--186},
shorttitle = {Systems, Man, and Cybernetics, Part C: Application},
title = {{Social Interactions in HRI: The Robot View}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1291665},
volume = {34},
year = {2004}
}
@article{breazeal2006using,
abstract = {This paper addresses an important issue in learning from demonstrations that are provided by “na\"{\i}ve” human teachers—people who do not have expertise in the machine learning algorithms used by the robot. We therefore entertain the possibility that, whereas the average human user may provide sensible demonstrations from a human’s perspective, these same demonstrations may be insufficient, incomplete, ambiguous, or otherwise “flawed” from the perspective of the training set needed by the learning algorithm to generalize properly. To address this issue, we present a system where the robot is modeled as a socially engaged and socially cognitive learner. We illustrate the merits of this approach through an example where the robot is able to correctly learn from “flawed” demonstrations by taking the visual perspective of the human instructor to clarify potential ambiguities.},
author = {Breazeal, Cynthia and Berlin, Matt and Brooks, Andrew and Gray, Jesse and Thomaz, Andrea L},
journal = {Robotics and Autonomous Systems},
number = {5},
pages = {385--393},
publisher = {Elsevier},
title = {{Using perspective taking to learn from ambiguous demonstrations}},
volume = {54},
year = {2006}
}
@article{browne2012learning,
author = {Browne, Katie and Nicolescu, Monica},
journal = {Cybernetics and Information Technologies},
number = {3},
pages = {27--38},
title = {{Learning to Generalize from Demonstrations}},
volume = {12},
year = {2012}
}
@article{chernova2010confidence,
abstract = {Learning from demonstration algorithms enable a robot to learn a new policy based on demonstrations provided by a teacher. In this article, we explore a novel research direction, multi-robot learning from demonstration, which extends demonstration based learning methods to collaborative multi-robot domains. Specifically, we study the problem of enabling a single person to teach individual policies to multiple robots at the same time. We present flexMLfD, a task and platform independent multi-robot demonstration learning framework that supports both independent and collaborative multi-robot behaviors. Building upon this framework, we contribute three approaches to teaching collaborative multi-robot behaviors based on different information sharing strategies, and evaluate these approaches by teaching two Sony QRIO humanoid robots to perform three collaborative ball sorting tasks. We then present scalability analysis of flexMLfD using up to seven Sony AIBO robots. We conclude the article by proposing a formalization for a broader multi-robot learning from demonstration research area.},
author = {Chernova, Sonia and Veloso, Manuela},
journal = {International Journal of Social Robotics},
number = {2},
pages = {195--215},
publisher = {Springer},
title = {{Confidence-based multi-robot learning from demonstration}},
volume = {2},
year = {2010}
}
@inproceedings{Demirdjian2005,
author = {Demirdjian, D. and Taycher, L. and Shakhnarovich, G. and Grauman, K. and Darrell, T.},
booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
doi = {10.1109/ICCV.2005.41},
isbn = {0-7695-2334-X},
issn = {1550-5499},
keywords = {Artificial intelligence,Bandwidth,Bayesian methods,Computer science,Humans,Laboratories,Search methods,Shape,State-space methods,Tracking,example-based matching,full posterior model,image matching,likelihood function,likelihood modes,local refinement,maximum likelihood estimation,posterior estimate,real image,streetlight effect,synthetic image,tracking task},
language = {English},
pages = {357--364 Vol. 1},
publisher = {IEEE},
title = {{Avoiding the "streetlight effect": tracking by exploring likelihood modes}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1541278},
volume = {1},
year = {2005}
}
@article{DeyuanQiu,
author = {{Deyuan Qiu}, Stefan May, Andreas N\"{u}chter},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deyuan Qiu - Unknown - GPU-Accelerated nearest neighbor search for 3d registration.pdf:pdf},
title = {{GPU-Accelerated nearest neighbor search for 3d registration}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.323.7141}
}
@inproceedings{Ganapathi2010,
author = {Ganapathi, Varun and Plagemann, Christian and Koller, Daphne and Thrun, Sebastian},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540141},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Biological system modeling,Cameras,Computer science,Filtering algorithms,Graphics,Humans,Kinematics,Layout,Motion analysis,Tracking,filtering algorithm,filtering theory,human pose markerless tracking,kinematic chain,local model-based search,monocular depth image,motion estimation,pose estimation,programmable graphics hardware,real time motion capture,single time-of-flight camera,unscented transform},
language = {English},
month = jun,
pages = {755--762},
publisher = {IEEE},
title = {{Real time motion capture using a single time-of-flight camera}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5540141},
year = {2010}
}
@inproceedings{Garcia2008,
author = {Garcia, Vincent and Debreuve, Eric and Barlaud, Michel},
booktitle = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
doi = {10.1109/CVPRW.2008.4563100},
isbn = {978-1-4244-2339-2},
issn = {2160-7508},
keywords = {Binary trees,Concurrent computing,Density measurement,Entropy,GPU,Graphics,Image retrieval,Information retrieval,Information theory,Kullback-Leibler divergence,Libraries,NVIDIA CUDA API,Nearest neighbor searches,approximated nearest neighbor library,brute force algorithm,computer graphics,efficient variable-bandwidth kernel-based estimato,fast k nearest neighbor search,graphics processing units,image processing,image retrieval,information theory,quasi-linear behavior,search problems,statistical analysis,statistical measures,video object tracking,video processing,video signal processing},
language = {English},
month = jun,
pages = {1--6},
publisher = {IEEE},
title = {{Fast k nearest neighbor search using GPU}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4563100},
year = {2008}
}
@article{Harish2007,
abstract = {Large graphs involving millions of vertices are common in many practical applications and are challenging to process. Practical-time implementations using high-end computers are reported but are accessible only to a few. Graphics Processing Units (GPUs) of today have high computation power and low price. They have a restrictive programming model and are tricky to use. The G80 line of Nvidia GPUs can be treated as a SIMD processor array using the CUDA programming model. We present a few fundamental algorithms - including breadth first search, single source shortest path, and all-pairs shortest path - using CUDA on large graphs. We can compute the single source shortest path on a 10 million vertex graph in 1.5 seconds using the Nvidia 8800GTX GPU costing \$600. In some cases optimal sequential algorithm is not the fastest on the GPU architecture. GPUs have great potential as high-performance co-processors.},
author = {Harish, Pawan and Narayanan, P. J.},
isbn = {3-540-77219-7, 978-3-540-77219-4},
month = dec,
pages = {197--208},
publisher = {Springer-Verlag},
title = {{Accelerating large graph algorithms on the GPU using CUDA}},
url = {http://dl.acm.org/citation.cfm?id=1782174.1782200},
year = {2007}
}
@inproceedings{6943191,
author = {Hayes, B and Scassellati, B},
booktitle = {Intelligent Robots and Systems (IROS 2014), 2014 IEEE/RSJ International Conference on},
doi = {10.1109/IROS.2014.6943191},
keywords = {Markov processes;directed graphs;human-robot inter},
month = sep,
pages = {4442--4449},
title = {{Discovering task constraints through observation and active learning}},
year = {2014}
}
@article{Knoop2009,
abstract = {In this article, we present an approach for the fusion of 2d and 3d measurements for model-based person tracking, also known as Human Motion Capture. The applied body model is defined geometrically with generalized cylinders, and is set up hierarchically with connecting joints of different types. The joint model can be parameterized to control the degrees of freedom, adhesion and stiffness. This results in an articulated body model with constrained kinematic degrees of freedom. The fusion approach incorporates this model knowledge together with the measurements, and tracks the target body iteratively with an extended Iterative Closest Point (ICP) approach. Generally, the ICP is based on the concept of correspondences between measurements and model, which is normally exploited to incorporate 3d point cloud measurements. The concept has been generalized to represent and incorporate also 2d image space features. Together with the 3D point cloud from a 3d time-of-flight (ToF) camera, arbitrary features, derived from 2D camera images, are used in the fusion algorithm for tracking of the body. This gives complementary information about the tracked body, enabling not only tracking of depth motions but also turning movements of the human body, which is normally a hard problem for markerless human motion capture systems. The resulting tracking system, named VooDoo is used to track humans in a Human–Robot Interaction (HRI) context. We only rely on sensors on board the robot, i.e. the color camera, the ToF camera and a laser range finder. The system runs in realtime (∼20 Hz) and is able to robustly track a human in the vicinity of the robot.},
author = {Knoop, Steffen and Vacek, Stefan and Dillmann, R\"{u}diger},
doi = {10.1016/j.robot.2008.10.017},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {3D body model,Human motion capture,Human robot interaction,Sensor fusion,Time-of-flight},
month = mar,
number = {3},
pages = {321--329},
title = {{Fusion of 2d and 3d sensor data for articulated body tracking}},
url = {http://www.sciencedirect.com/science/article/pii/S0921889008001711},
volume = {57},
year = {2009}
}
@article{Montesano2008,
abstract = {Affordances encode relationships between actions, objects, and effects. They play an important role on basic cognitive capabilities such as prediction and planning. We address the problem of learning affordances through the interaction of a robot with the environment, a key step to understand the world properties and develop social skills. We present a general model for learning object affordances using Bayesian networks integrated within a general developmental architecture for social robots. Since learning is based on a probabilistic model, the approach is able to deal with uncertainty, redundancy, and irrelevant information. We demonstrate successful learning in the real world by having an humanoid robot interacting with objects. We illustrate the benefits of the acquired knowledge in imitation games.},
author = {Montesano, L. and Lopes, M. and Bernardino, a. and Santos-Victor, J.},
doi = {10.1109/TRO.2007.914848},
file = {:home/luke/Documents/cs790x/paperreviews/wk5/learning object affordances/04456755.pdf:pdf},
isbn = {1552-3098},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
keywords = {Affordances,biorobotics,cognitive robotics,humanoid robots,learning},
number = {1},
pages = {15--26},
title = {{Learning Object Affordances: From Sensory--Motor Coordination to Imitation}},
volume = {24},
year = {2008}
}
@article{Nicolescu2008,
author = {Nicolescu, Monica and {Chadwicke Jenkins}, Odest and Olenderski, Adam and Fritzinger, Eric},
doi = {10.1075/is.9.2.09nic},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nicolescu et al. - 2008 - Learning behavior fusion from demonstration.pdf:pdf},
issn = {15720373},
journal = {Interaction Studies},
pages = {319--352},
title = {{Learning behavior fusion from demonstration}},
volume = {9},
year = {2008}
}
@misc{Nvidia2014,
author = {Nvidia},
booktitle = {Programming Guides},
number = {August},
title = {{Cuda c programming guide}},
url = {http://docs.nvidia.com/cuda/cuda-c-programming-guide/\#axzz3Zs1OgRaO},
year = {2014}
}
@article{Ortega-Arranz2015,
abstract = {The single-source shortest path (SSSP) problem arises in many different fields. In this paper, we present a GPU SSSP algorithm implementation. Our work significantly speeds up the computation of the SSSP, not only with respect to a CPU-based version, but also to other state-of-the-art GPU implementations based on Dijkstra. Both GPU implementations have been evaluated using the latest NVIDIA architectures. The graphs chosen as input sets vary in nature, size, and fan-out degree, in order to evaluate the behavior of the algorithms for different data classes. Additionally, we have enhanced our GPU algorithm implementation using two optimization techniques: The use of a proper choice of threadblock size; and the modification of the GPU L1 cache memory state of NVIDIA devices. These optimizations lead to performance improvements of up to 23 \% with respect to the non-optimized versions. In addition, we have made a platform comparison of several NVIDIA boards in order to distinguish which one is better for each class of graphs, depending on their features. Finally, we compare our results with an optimized sequential implementation of Dijkstra’s algorithm included in the reference Boost library, obtaining an improvement ratio of up to 19},
author = {Ortega-Arranz, Hector and Torres, Yuri and Gonzalez-Escribano, Arturo and Llanos, Diego R.},
doi = {10.1007/s10766-015-0351-z},
issn = {0885-7458},
journal = {International Journal of Parallel Programming},
keywords = {Boost library,Dijkstra,GPGPU,Kernel characterization,NVIDIA platform comparison,Optimization techniques,SSSP},
month = feb,
title = {{Comprehensive Evaluation of a New GPU-based Approach to the Shortest Path Problem}},
url = {http://link.springer.com/10.1007/s10766-015-0351-z},
year = {2015}
}
@article{Ortega-Arranz2013a,
author = {Ortega-Arranz, Hector and Torres, Yuri and Llanos, Diego R. and Gonzalez-Escribano, Arturo},
month = jun,
title = {{The All-Pair Shortest-Path Problem in Shared-Memory Heterogeneous Systems}},
url = {http://www.researchgate.net/publication/237149091\_The\_All-Pair\_Shortest-Path\_Problem\_in\_Shared-Memory\_Heterogeneous\_Systems},
year = {2013}
}
@inproceedings{Ortega-Arranz2013,
author = {Ortega-Arranz, Hector and Torres, Yuri and Llanos, Diego R. and Gonzalez-Escribano, Arturo},
booktitle = {2013 International Conference on High Performance Computing \& Simulation (HPCS)},
doi = {10.1109/HPCSim.2013.6641461},
isbn = {978-1-4799-0838-7},
keywords = {CPU-based version,Complexity theory,Computer architecture,Dijkstra,Dijkstra-based GPU implementation,Economics,GPU,GPU- based version,GPU-Crauser algorithm,GPU-Martin algorithm,GPU-based approach,Graphics processing units,Kepler,Kernel,NSSP,Nvidia architecture,Parallel Algorithms,Parallel processing,SSSP,SSSP problem,Vectors,graphics processing units,multiprocessing systems,parallel architectures,performance gain,shortest path problem,single-source shortest path problem},
language = {English},
month = jul,
pages = {505--511},
publisher = {IEEE},
title = {{A new GPU-based approach to the Shortest Path problem}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6641461},
year = {2013}
}
@inproceedings{Plagemann2010,
author = {Plagemann, Christian and Ganapathi, Varun and Koller, Daphne and Thrun, Sebastian},
booktitle = {2010 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2010.5509559},
isbn = {978-1-4244-5038-1},
issn = {1050-4729},
keywords = {3D orientation vector estimation,Cameras,Detectors,Head,Humans,Image sensors,Layout,Motion detection,Shape,Skeleton,USA Councils,active motion capture system,body part detection,body part identification,body part localization,classification problem,depth image,geodesic extrema,ground truth label,human shape analysis,image classification,image motion analysis,interest point detector,local shape descriptor,mesh generation,object detection,shape recognition,surface mesh,video frame rate,video signal processing},
language = {English},
month = may,
pages = {3108--3113},
publisher = {IEEE},
title = {{Real-time identification and localization of body parts from depth images}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5509559},
year = {2010}
}
@inproceedings{Toss2014,
author = {Toss, Julio and Comba, Joao Luiz Dihl and Raffin, Bruno},
booktitle = {2014 27th SIBGRAPI Conference on Graphics, Patterns and Images},
doi = {10.1109/SIBGRAPI.2014.1},
isbn = {978-1-4799-4258-9},
keywords = {3D images,Algorithm design and analysis,Computational modeling,GPGPU,GPU algorithm,Graphics processing units,Indexes,Instruction sets,Materials,Parallel Programming,Physics Based Simulation,Topology,Voronoi Diagram,Voronoi computation,Voronoi diagrams,computational geometry,data structures,generalized distance functions,graph,graph theory,graphics processing units,interactive topological changes,nonEuclidean distances,parallel shortest path algorithm,real time physics engines,shortest-path algorithm,soft object simulation algorithms,virtual surgery simulations},
language = {English},
month = aug,
pages = {212--219},
publisher = {IEEE},
title = {{Parallel Shortest Path Algorithm for Voronoi Diagrams with Generalized Distance Functions}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6915310},
year = {2014}
}
@article{Towle2014,
abstract = {Service robots have the potential of improving the quality of life and assist with people’s daily activities. Such robots must be capable of operating over long periods of time, performingmultiple tasks, and scheduling them appro- priately for execution. In addition, service robots must be capable of dealing with tasks whose goals may be in conflict with each other and would need to determine, dynamically, which task to pursue in such a case. Adding to the complex- ity of the problem is the fact that some task requests may have time constraints—deadlines by which the task has to be completed. Given the dynamic nature of the environment, the robots must make decisions on what tasks to pursue in situ- ations where there could be incomplete or missing informa- tion. The robots should also be capable of accepting requests for new tasks or services at runtime, while possibly working on another task. In order to achieve these requirements, this paper presents the Auction Behavior-Based Robotic Archi- tecture that brings the following contributions: (1) it uses an auction mechanism to determine the relevance of a task to run at any given time, (2) it handles multiple user requests while dealing with potentially critical time constraints and incom- plete information, (3) it enables long-term robot operation and (4) it allows for dynamic assignment of new tasks. The proposed system is validated on a physical robotic platform, the Segway RMP? and in simulation.},
author = {Towle, Bradford a. and Nicolescu, Monica},
doi = {10.1007/s11370-013-0141-7},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Towle, Nicolescu - 2014 - An auction behavior-based robotic architecture for service robotics.pdf:pdf},
isbn = {9781601321855},
issn = {18612784},
journal = {Intelligent Service Robotics},
keywords = {Auction-based robotic architecture,Behavior-based robotics,Dynamic time and environmental constraints,Intelligent action selection},
pages = {157--174},
title = {{An auction behavior-based robotic architecture for service robotics}},
volume = {7},
year = {2014}
}
@inproceedings{export:145347,
abstract = {<p>We propose a new method to quickly and accurately predict 3D positions of body
joints from a single depth image, using no temporal information. We take an
object recognition approach, designing an intermediate body parts representation
that maps the difficult pose estimation problem into a simpler per-pixel
classification problem. Our large and highly varied training dataset allows the
classifier to estimate body parts invariant to pose, body shape, clothing, etc.
Finally we generate confidence-scored 3D proposals of several body joints by
reprojecting the classification result and finding local modes.
The system runs
at 200 frames per second on consumer hardware. Our evaluation shows high accuracy
on both synthetic and real test sets, and investigates the effect of several
training parameters. We achieve state of the art accuracy in our comparison with
related work and demonstrate improved generalization over exact whole-skeleton
nearest neighbor matching.</p>},
author = {Shotton, Jamie and Fitzgibbon, Andrew and Cook, Mat and Sharp, Toby and Finocchio, Mark and Moore, Richard and Kipman, Alex and Blake, Andrew},
booktitle = {CVPR},
month = jun,
publisher = {IEEE},
title = {{Real-Time Human Pose Recognition in Parts from a Single Depth Image}},
url = {http://research.microsoft.com/apps/pubs/default.aspx?id=145347},
year = {2011}
}
