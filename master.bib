@article{DeyuanQiu,
author = {{Deyuan Qiu}, Stefan May, Andreas N{\"{u}}chter and {Deyuan Qiu Stefan May}, Andreas N{\"{u}}chter},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deyuan Qiu - Unknown - GPU-Accelerated nearest neighbor search for 3d registration.pdf:pdf},
title = {{GPU-Accelerated nearest neighbor search for 3d registration}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.323.7141}
}
@article{browne2012learning,
abstract = {Learning by demonstration is a natural approach that can be used to transfer knowledge from humans to robots, similar to how people teach each other through examples. To date, numerous approaches have been developed for learning by demonstration, focusing on two main aspects of the learning problem: the teaching of "motor skills" and the transfer of high-level knowledge of "tasks". This thesis focused on the topic of high-level task learning. Currently, approaches that address this problem utilize the assumption that the task to be learned consists of a precise sequencing of steps that need to be executed. The methods, therefore, aim to accurately reproduce an exact copy of the provided demonstration. However, these methods may suffer from overspecializations or misinterpretations of the task to be learned, if there is any variation in the training example. This variation could be due to the fact that demonstrations can be affected by noise or even by significant changes in task structure from one training example to another. This thesis presents an approach to addressing this challenge through generalization, from a small number of demonstrations of the same task. The aim is to extract a task representation that encodes the essential information from all the training examples, in the presence of small or even large variation in the training examples. The proposed solution consists of two main components: a representation that enables the learner to store the generalized representation of the task and the learning algorithm that allows the construction of a generalized task representation. The approach is validated in simulation and on a physical robot working in the real world, showing the ability to generalize to a wide range of scenarios that may typically occur in teaching by demonstration.},
address = {New York, New York, USA},
author = {Browne, Katie and Nicolescu, Monica and Baak, Andreas and Muller, Meinard and Bharaj, Gaurav and Seidel, Hans-Peter and Theobalt, Christian and {Barry Brian Werger}, Maja J. Mataric and Bicho, Estela and Erlhagen, Wolfram and Louro, Lu{\'{i}}s and {Costa e Silva}, Eliana and Silva, Rui and Hip{\'{o}}lito, Nzoji and Bleiweiss, Amit and Kutliroff, Eran Eilat Gershom and Breazeal, Cynthia and Berlin, Matt and Brooks, Andrew and Gray, Jesse and Thomaz, Andrea L and Browne, Katie and Nicolescu, Monica and Chernova, Sonia and Veloso, Manuela and Demirdjian, D. and Taycher, L. and Shakhnarovich, G. and Grauman, K. and Darrell, T. and {Deyuan Qiu Stefan May}, Andreas N{\"{u}}chter and Ganapathi, Varun and Plagemann, Christian and Koller, Daphne and Thrun, Sebastian and Hayes, Bradley and Scassellati, Brian and Garcia, Vincent and Debreuve, Eric and Barlaud, Michel and Harish, Pawan and Narayanan, P. J. and Hawkins, Kelsey P. and Bansal, Shray and Vo, Nam N. and Bobick, Aaron F. and Bansal, Shray and Bobic, Aaron F. and Knoop, Steffen and Vacek, Stefan and Dillmann, R{\"{u}}diger and Montesano, L. and Lopes, M. and Bernardino, a. and Santos-Victor, J. and Nicolescu, Monica and {Chadwicke Jenkins}, Odest and Olenderski, Adam and Fritzinger, Eric and Nvidia and Ortega-Arranz, Hector and Torres, Yuri and Gonzalez-Escribano, Arturo and Llanos, Diego R. and Gonzalez-Escribano, Arturo and Plagemann, Christian and Ganapathi, Varun and Koller, Daphne and Thrun, Sebastian and Shotton, Jamie and Fitzgibbon, Andrew and Cook, Mat and Sharp, Toby and Finocchio, Mark and Moore, Richard and Kipman, Alex and Blake, Andrew and Toss, Julio and Comba, Joao Luiz Dihl and Raffin, Bruno and Towle, Bradford a. and Nicolescu, Monica and Rocha, Joaquim},
doi = {10.2478/cait-2012-0019},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barry Brian Werger - Unknown - Broadcast of Local Eligibility for Multi-Target Observation.pdf:pdf;:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hayes, Scassellati - Unknown - Discovering Task Constraints Through Observation and Active Learning.pdf:pdf;:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bicho et al. - 2011 - A dynamic field approach to goal inference, error detection and anticipatory action selection in human-robot colla.pdf:pdf;:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nicolescu et al. - 2008 - Learning behavior fusion from demonstration.pdf:pdf;:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Towle, Nicolescu - 2014 - An auction behavior-based robotic architecture for service robotics.pdf:pdf;:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Montesano et al. - 2008 - Learning Object Affordances From Sensory--Motor Coordination to Imitation.pdf:pdf;:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deyuan Qiu - Unknown - GPU-Accelerated nearest neighbor search for 3d registration.pdf:pdf},
isbn = {9781303171772},
issn = {13119702},
journal = {Cybernetics and Information Technologies},
keywords = {3D body model,3D images,3D orientation vector estimation,3D pose estimation,AND-OR tree structure,Action selection,Affordances,Algorithm design and analysis,Anticipation,Application software,Artificial intelligence,Auction-based robotic architecture,Bandwidth,Bayesian methods,Behavior graphs,Behavior-based robotics,Binary trees,Biological system modeling,Boost library,CPU-based version,Cameras,Complexity theory,Computational modeling,Computer architecture,Computer science,Concurrent computing,Databases,Density measurement,Detectors,Dijkstra,Dijkstra's algorithm,Dijkstra-based GPU implementation,Dynamic Fields,Dynamic time and environmental constraints,Economics,Entropy,Error detection,Estimation,Filtering algorithms,GPGPU,GPU,GPU algorithm,GPU- based version,GPU-Crauser algorithm,GPU-Martin algorithm,GPU-based approach,Generalized representation,Goal inference,Graph task representation,Graphics,Graphics processing units,HCI,HRI,Head,Hidden Markov models,Human computer interaction,Human motion capture,Human robot interaction,Human-robot collaboration,Human-robot interaction,Humanoid robots,Humans,Image retrieval,Image sensors,Indexes,Information retrieval,Information theory,Instruction sets,Intelligent action selection,Joints,Kepler,Kernel,Kernel characterization,Kinematics,Kullback-Leibler divergence,Laboratories,Layout,Learning by Demonstration,Libraries,Materials,Motion analysis,Motion detection,NSSP,NVIDIA CUDA API,NVIDIA platform comparison,Nearest neighbor searches,Nvidia architecture,Optimization,Optimization techniques,Orbital robotics,Parallel Algorithms,Parallel Programming,Parallel processing,Petroleum,Physics Based Simulation,Planets,Positron emission tomography,Probabilistic logic,Robot sensing systems,Robotics,SSSP,SSSP problem,Search methods,Senior citizens,Sensor fusion,Sensors,Service robots,Shape,Skeleton,State-space methods,Time-of-flight,Timing,Topology,Torso,Tracking,USA Councils,Vectors,Voronoi Diagram,Voronoi computation,Voronoi diagrams,Wait times,active motion capture system,approximated nearest neighbor library,autonomous robots design,biorobotics,body part detection,body part identification,body part localization,brute force algorithm,cameras,classification problem,cognitive robotics,computational geometry,computer graphics,data structures,data-driven approach,data-driven hybrid strategy,depth camera,depth data,depth image,desktop computer,efficient variable-bandwidth kernel-based estimato,example-based matching,fast k nearest neighbor search,filtering algorithm,filtering theory,full posterior model,full-body motion tracking,generalized distance functions,geodesic extrema,global pose estimates,global retrieval techniques,graph,graph theory,graphics processing units,ground truth label,human actions anticipation,human computer interaction,human pose markerless tracking,human shape analysis,human-computer interaction,human-robot interaction,human-robot performance,humanoid robots,image classification,image matching,image motion analysis,image processing,image reconstruction,image retrieval,inference mechanisms,inference methods,information theory,interactive topological changes,interest point detector,kinematic chain,learning,learning (artificial intelligence),likelihood function,likelihood modes,local model-based search,local pose estimates,local refinement,local shape descriptor,maximum likelihood estimation,mesh generation,microcomputers,monocular 2.5D depth images,monocular depth image,motion estimation,multiprocessing systems,nonEuclidean distances,object detection,object tracking,optional robot action,parallel architectures,parallel shortest path algorithm,partially ordered robot action,performance gain,pose estimation,pose features,posterior estimate,probabilistic graphical model,programmable graphics hardware,quasi-linear behavior,real image,real time motion capture,real time physics engines,real-time frame rates,real-time full body pose reconstruction,real-time tracking,robot execution system,robot planning,robot view,robots,search problems,self-occlusions,sensing information,shape recognition,shortest path problem,shortest-path algorithm,single depth image stream,single time-of-flight camera,single-source shortest path problem,social robot partner,socially guided learning,soft object simulation algorithms,sparse Hausdorff distance,statistical analysis,statistical measures,streetlight effect,structured activities representation,surface mesh,synthetic image,task structure,task variation,tracking task,trees (mathematics),two-way-branch assembly task,unscented transform,video frame rate,video object tracking,video processing,video signal processing,virtual surgery simulations},
language = {English},
month = {jun},
number = {3},
pages = {27--38},
publisher = {IEEE},
shorttitle = {Robotics and Automation (ICRA), 2014 IEEE Internat},
title = {{Learning to generalize from demonstrations}},
url = {https://github.com/joaquimrocha/Skeltrack http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6915310 http://research.microsoft.com/apps/pubs/default.aspx?id=145347 http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5509559 http://www.researchgate.},
volume = {12},
year = {2012}
}
@misc{Hawkins,
abstract = {Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.},
author = {Hawkins, Kelsey P. and Vo, Nam and Bansal, Shray and Bobic, Aaron F.},
keywords = {Human-robot collaboration,Sensors,Wait times},
publisher = {Institute of Electrical and Electronics Engineers},
title = {{Probabilistic Human Action Prediction and Wait-sensitive Planning for Responsive Human-robot Collaboration}},
url = {https://smartech.gatech.edu/handle/1853/50890}
}
@inproceedings{Hawkins2014,
abstract = {A representation for structured activities is developed that allows a robot to probabilistically infer which task actions a human is currently performing and to predict which future actions will be executed and when they will occur. The goal is to enable a robot to anticipate collaborative actions in the presence of uncertain sensing and task ambiguity. The system can represent multi-path tasks where the task variations may contain partially ordered actions or even optional actions that may be skipped altogether. The task is represented by an AND-OR tree structure from which a probabilistic graphical model is constructed. Inference methods for that model are derived that support a planning and execution system for the robot which attempts to minimize a cost function based upon expected human idle time. We demonstrate the theory in both simulation and actual human-robot performance of a two-way-branch assembly task. In particular we show that the inference model can robustly anticipate the actions of the human even in the presence of unreliable or noisy detections because of its integration of all its sensing information along with knowledge of task structure.},
author = {Hawkins, Kelsey P. and Bansal, Shray and Vo, Nam N. and Bobick, Aaron F.},
booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2014.6907165},
isbn = {978-1-4799-3685-4},
keywords = {AND-OR tree structure,Detectors,Hidden Markov models,Probabilistic logic,Robot sensing systems,Timing,human actions anticipation,human-robot interaction,human-robot performance,inference mechanisms,inference methods,optional robot action,partially ordered robot action,probabilistic graphical model,robot execution system,robot planning,sensing information,structured activities representation,task structure,task variation,trees (mathematics),two-way-branch assembly task},
month = {may},
pages = {2215--2222},
publisher = {IEEE},
shorttitle = {Robotics and Automation (ICRA), 2014 IEEE Internat},
title = {{Anticipating human actions for collaboration in the presence of task and sensor uncertainty}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6907165},
year = {2014}
}
@inproceedings{export:145347,
abstract = {{\textless}p{\textgreater}We propose a new method to quickly and accurately predict 3D positions of body
joints from a single depth image, using no temporal information. We take an
object recognition approach, designing an intermediate body parts representation
that maps the difficult pose estimation problem into a simpler per-pixel
classification problem. Our large and highly varied training dataset allows the
classifier to estimate body parts invariant to pose, body shape, clothing, etc.
Finally we generate confidence-scored 3D proposals of several body joints by
reprojecting the classification result and finding local modes.
The system runs
at 200 frames per second on consumer hardware. Our evaluation shows high accuracy
on both synthetic and real test sets, and investigates the effect of several
training parameters. We achieve state of the art accuracy in our comparison with
related work and demonstrate improved generalization over exact whole-skeleton
nearest neighbor matching.{\textless}/p{\textgreater}},
author = {Shotton, Jamie and Fitzgibbon, Andrew and Cook, Mat and Sharp, Toby and Finocchio, Mark and Moore, Richard and Kipman, Alex and Blake, Andrew},
booktitle = {CVPR},
month = {jun},
publisher = {IEEE},
title = {{Real-Time Human Pose Recognition in Parts from a Single Depth Image}},
url = {http://research.microsoft.com/apps/pubs/default.aspx?id=145347},
year = {2011}
}
@misc{Nvidia2014,
author = {Nvidia},
booktitle = {Programming Guides},
number = {August},
title = {{Cuda c programming guide}},
url = {http://docs.nvidia.com/cuda/cuda-c-programming-guide/{\#}axzz3Zs1OgRaO},
year = {2014}
}
@inproceedings{Garcia2008,
author = {Garcia, Vincent and Debreuve, Eric and Barlaud, Michel},
booktitle = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
doi = {10.1109/CVPRW.2008.4563100},
isbn = {978-1-4244-2339-2},
issn = {2160-7508},
keywords = {Binary trees,Concurrent computing,Density measurement,Entropy,GPU,Graphics,Image retrieval,Information retrieval,Information theory,Kullback-Leibler divergence,Libraries,NVIDIA CUDA API,Nearest neighbor searches,approximated nearest neighbor library,brute force algorithm,computer graphics,efficient variable-bandwidth kernel-based estimato,fast k nearest neighbor search,graphics processing units,image processing,image retrieval,information theory,quasi-linear behavior,search problems,statistical analysis,statistical measures,video object tracking,video processing,video signal processing},
language = {English},
month = {jun},
pages = {1--6},
publisher = {IEEE},
title = {{Fast k nearest neighbor search using GPU}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4563100},
year = {2008}
}
@article{Ortega-Arranz2013a,
author = {Ortega-Arranz, Hector and Torres, Yuri and Llanos, Diego R. and Gonzalez-Escribano, Arturo},
month = {jun},
title = {{The All-Pair Shortest-Path Problem in Shared-Memory Heterogeneous Systems}},
url = {http://www.researchgate.net/publication/237149091{\_}The{\_}All-Pair{\_}Shortest-Path{\_}Problem{\_}in{\_}Shared-Memory{\_}Heterogeneous{\_}Systems},
year = {2013}
}
@inproceedings{Toss2014,
author = {Toss, Julio and Comba, Joao Luiz Dihl and Raffin, Bruno},
booktitle = {2014 27th SIBGRAPI Conference on Graphics, Patterns and Images},
doi = {10.1109/SIBGRAPI.2014.1},
isbn = {978-1-4799-4258-9},
keywords = {3D images,Algorithm design and analysis,Computational modeling,GPGPU,GPU algorithm,Graphics processing units,Indexes,Instruction sets,Materials,Parallel Programming,Physics Based Simulation,Topology,Voronoi Diagram,Voronoi computation,Voronoi diagrams,computational geometry,data structures,generalized distance functions,graph,graph theory,graphics processing units,interactive topological changes,nonEuclidean distances,parallel shortest path algorithm,real time physics engines,shortest-path algorithm,soft object simulation algorithms,virtual surgery simulations},
language = {English},
month = {aug},
pages = {212--219},
publisher = {IEEE},
title = {{Parallel Shortest Path Algorithm for Voronoi Diagrams with Generalized Distance Functions}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6915310},
year = {2014}
}
@article{Harish2007,
abstract = {Large graphs involving millions of vertices are common in many practical applications and are challenging to process. Practical-time implementations using high-end computers are reported but are accessible only to a few. Graphics Processing Units (GPUs) of today have high computation power and low price. They have a restrictive programming model and are tricky to use. The G80 line of Nvidia GPUs can be treated as a SIMD processor array using the CUDA programming model. We present a few fundamental algorithms - including breadth first search, single source shortest path, and all-pairs shortest path - using CUDA on large graphs. We can compute the single source shortest path on a 10 million vertex graph in 1.5 seconds using the Nvidia 8800GTX GPU costing {\$}600. In some cases optimal sequential algorithm is not the fastest on the GPU architecture. GPUs have great potential as high-performance co-processors.},
author = {Harish, Pawan and Narayanan, P. J.},
isbn = {3-540-77219-7, 978-3-540-77219-4},
month = {dec},
pages = {197--208},
publisher = {Springer-Verlag},
title = {{Accelerating large graph algorithms on the GPU using CUDA}},
url = {http://dl.acm.org/citation.cfm?id=1782174.1782200},
year = {2007}
}
@inproceedings{Ganapathi2010,
author = {Ganapathi, Varun and Plagemann, Christian and Koller, Daphne and Thrun, Sebastian},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540141},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Biological system modeling,Cameras,Computer science,Filtering algorithms,Graphics,Humans,Kinematics,Layout,Motion analysis,Tracking,filtering algorithm,filtering theory,human pose markerless tracking,kinematic chain,local model-based search,monocular depth image,motion estimation,pose estimation,programmable graphics hardware,real time motion capture,single time-of-flight camera,unscented transform},
language = {English},
month = {jun},
pages = {755--762},
publisher = {IEEE},
title = {{Real time motion capture using a single time-of-flight camera}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5540141},
year = {2010}
}
@inproceedings{Bleiweiss2009,
address = {New York, New York, USA},
author = {Bleiweiss, Amit and Kutliroff, Eran Eilat Gershom},
booktitle = {ACM SIGGRAPH ASIA 2009 Sketches on - SIGGRAPH ASIA '09},
doi = {10.1145/1667146.1667172},
month = {dec},
pages = {1},
publisher = {ACM Press},
title = {{Markerless motion capture using a single depth sensor}},
url = {http://dl.acm.org/citation.cfm?id=1667146.1667172},
year = {2009}
}
@inproceedings{Demirdjian2005,
author = {Demirdjian, D. and Taycher, L. and Shakhnarovich, G. and Grauman, K. and Darrell, T.},
booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
doi = {10.1109/ICCV.2005.41},
isbn = {0-7695-2334-X},
issn = {1550-5499},
keywords = {Artificial intelligence,Bandwidth,Bayesian methods,Computer science,Humans,Laboratories,Search methods,Shape,State-space methods,Tracking,example-based matching,full posterior model,image matching,likelihood function,likelihood modes,local refinement,maximum likelihood estimation,posterior estimate,real image,streetlight effect,synthetic image,tracking task},
language = {English},
pages = {357--364 Vol. 1},
publisher = {IEEE},
title = {{Avoiding the "streetlight effect": tracking by exploring likelihood modes}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1541278},
volume = {1},
year = {2005}
}
@article{Knoop2009,
abstract = {In this article, we present an approach for the fusion of 2d and 3d measurements for model-based person tracking, also known as Human Motion Capture. The applied body model is defined geometrically with generalized cylinders, and is set up hierarchically with connecting joints of different types. The joint model can be parameterized to control the degrees of freedom, adhesion and stiffness. This results in an articulated body model with constrained kinematic degrees of freedom. The fusion approach incorporates this model knowledge together with the measurements, and tracks the target body iteratively with an extended Iterative Closest Point (ICP) approach. Generally, the ICP is based on the concept of correspondences between measurements and model, which is normally exploited to incorporate 3d point cloud measurements. The concept has been generalized to represent and incorporate also 2d image space features. Together with the 3D point cloud from a 3d time-of-flight (ToF) camera, arbitrary features, derived from 2D camera images, are used in the fusion algorithm for tracking of the body. This gives complementary information about the tracked body, enabling not only tracking of depth motions but also turning movements of the human body, which is normally a hard problem for markerless human motion capture systems. The resulting tracking system, named VooDoo is used to track humans in a Human–Robot Interaction (HRI) context. We only rely on sensors on board the robot, i.e. the color camera, the ToF camera and a laser range finder. The system runs in realtime (∼20 Hz) and is able to robustly track a human in the vicinity of the robot.},
author = {Knoop, Steffen and Vacek, Stefan and Dillmann, R{\"{u}}diger},
doi = {10.1016/j.robot.2008.10.017},
issn = {09218890},
journal = {Robotics and Autonomous Systems},
keywords = {3D body model,Human motion capture,Human robot interaction,Sensor fusion,Time-of-flight},
month = {mar},
number = {3},
pages = {321--329},
title = {{Fusion of 2d and 3d sensor data for articulated body tracking}},
url = {http://www.sciencedirect.com/science/article/pii/S0921889008001711},
volume = {57},
year = {2009}
}
@inproceedings{Plagemann2010,
author = {Plagemann, Christian and Ganapathi, Varun and Koller, Daphne and Thrun, Sebastian},
booktitle = {2010 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2010.5509559},
isbn = {978-1-4244-5038-1},
issn = {1050-4729},
keywords = {3D orientation vector estimation,Cameras,Detectors,Head,Humans,Image sensors,Layout,Motion detection,Shape,Skeleton,USA Councils,active motion capture system,body part detection,body part identification,body part localization,classification problem,depth image,geodesic extrema,ground truth label,human shape analysis,image classification,image motion analysis,interest point detector,local shape descriptor,mesh generation,object detection,shape recognition,surface mesh,video frame rate,video signal processing},
language = {English},
month = {may},
pages = {3108--3113},
publisher = {IEEE},
title = {{Real-time identification and localization of body parts from depth images}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5509559},
year = {2010}
}
@article{breazeal2006using,
abstract = {This paper addresses an important issue in learning from demonstrations that are provided by “na{\"{i}}ve” human teachers—people who do not have expertise in the machine learning algorithms used by the robot. We therefore entertain the possibility that, whereas the average human user may provide sensible demonstrations from a human's perspective, these same demonstrations may be insufficient, incomplete, ambiguous, or otherwise “flawed” from the perspective of the training set needed by the learning algorithm to generalize properly. To address this issue, we present a system where the robot is modeled as a socially engaged and socially cognitive learner. We illustrate the merits of this approach through an example where the robot is able to correctly learn from “flawed” demonstrations by taking the visual perspective of the human instructor to clarify potential ambiguities.},
author = {Breazeal, Cynthia and Berlin, Matt and Brooks, Andrew and Gray, Jesse and Thomaz, Andrea L},
journal = {Robotics and Autonomous Systems},
number = {5},
pages = {385--393},
publisher = {Elsevier},
title = {{Using perspective taking to learn from ambiguous demonstrations}},
volume = {54},
year = {2006}
}
@article{chernova2010confidence,
abstract = {Learning from demonstration algorithms enable a robot to learn a new policy based on demonstrations provided by a teacher. In this article, we explore a novel research direction, multi-robot learning from demonstration, which extends demonstration based learning methods to collaborative multi-robot domains. Specifically, we study the problem of enabling a single person to teach individual policies to multiple robots at the same time. We present flexMLfD, a task and platform independent multi-robot demonstration learning framework that supports both independent and collaborative multi-robot behaviors. Building upon this framework, we contribute three approaches to teaching collaborative multi-robot behaviors based on different information sharing strategies, and evaluate these approaches by teaching two Sony QRIO humanoid robots to perform three collaborative ball sorting tasks. We then present scalability analysis of flexMLfD using up to seven Sony AIBO robots. We conclude the article by proposing a formalization for a broader multi-robot learning from demonstration research area.},
author = {Chernova, Sonia and Veloso, Manuela},
journal = {International Journal of Social Robotics},
number = {2},
pages = {195--215},
publisher = {Springer},
title = {{Confidence-based multi-robot learning from demonstration}},
volume = {2},
year = {2010}
}
@inproceedings{Baak2011,
abstract = {In recent years, depth cameras have become a widely available sensor type that captures depth images at real-time frame rates. Even though recent approaches have shown that 3D pose estimation from monocular 2.5D depth images has become feasible, there are still challenging problems due to strong noise in the depth data and self-occlusions in the motions being captured. In this paper, we present an efficient and robust pose estimation framework for tracking full-body motions from a single depth image stream. Following a data-driven hybrid strategy that combines local optimization with global retrieval techniques, we contribute several technical improvements that lead to speed-ups of an order of magnitude compared to previous approaches. In particular, we introduce a variant of Dijkstra's algorithm to efficiently extract pose features from the depth data and describe a novel late-fusion scheme based on an efficiently computable sparse Hausdorff distance to combine local and global pose estimates. Our experiments show that the combination of these techniques facilitates real-time tracking with stable results even for fast and complex motions, making it applicable to a wide range of inter-active scenarios.},
author = {Baak, Andreas and Muller, Meinard and Bharaj, Gaurav and Seidel, Hans Peter and Theobalt, Christian},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2011.6126356},
isbn = {9781457711015},
issn = {1550-5499},
keywords = {3D pose estimation,Cameras,Databases,Dijkstra's algorithm,Estimation,Joints,Optimization,Torso,Tracking,cameras,data-driven approach,data-driven hybrid strategy,depth camera,depth data,full-body motion tracking,global pose estimates,global retrieval techniques,image motion analysis,image reconstruction,local pose estimates,monocular 2.5D depth images,object tracking,pose estimation,pose features,real-time frame rates,real-time full body pose reconstruction,real-time tracking,self-occlusions,single depth image stream,sparse Hausdorff distance},
language = {English},
month = {nov},
pages = {1092--1099},
publisher = {IEEE},
title = {{A data-driven approach for real-time full body pose reconstruction from a depth camera}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6126356},
year = {2011}
}
@article{Breazeal2004,
abstract = {This paper explores the topic of human-robot interaction (HRI) from the perspective of designing sociable autonomous robots-robots designed to interact with people in a human-like way. There are a growing number of applications for robots that people can engage as capable creatures or as partners rather than tools, yet little is understood about how to best design robots that interact with people in this way. The related field of human-computer interaction (HCI) offers important insights, however autonomous robots are a very different technology from desktop computers. In this paper, we look at the field of HRI from an HCI perspective, pointing out important similarities yet significant differences that may ultimately make HRI a distinct area of inquiry. One outcome of this discussion is that it is important to view the design and evaluation problem from the robot's perspective as well as that of the human. Taken as a whole, this paper provides a framework with which to design and evaluate sociable robots from a HRI perspective.},
author = {Breazeal, C.},
doi = {10.1109/TSMCC.2004.826268},
issn = {1094-6977},
journal = {IEEE Transactions on Systems, Man and Cybernetics, Part C (Applications and Reviews)},
keywords = {Application software,HCI,HRI,Human computer interaction,Human robot interaction,Humanoid robots,Orbital robotics,Petroleum,Planets,Positron emission tomography,Senior citizens,Service robots,autonomous robots design,desktop computer,human computer interaction,human-computer interaction,human-robot interaction,learning (artificial intelligence),microcomputers,robot view,robots,social robot partner,socially guided learning},
month = {may},
number = {2},
pages = {181--186},
shorttitle = {Systems, Man, and Cybernetics, Part C: Application},
title = {{Social Interactions in HRI: The Robot View}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1291665},
volume = {34},
year = {2004}
}
@inproceedings{6943191,
author = {Hayes, B and Scassellati, B},
booktitle = {Intelligent Robots and Systems (IROS 2014), 2014 IEEE/RSJ International Conference on},
doi = {10.1109/IROS.2014.6943191},
keywords = {Markov processes;directed graphs;human-robot inter},
month = {sep},
pages = {4442--4449},
title = {{Discovering task constraints through observation and active learning}},
year = {2014}
}
@article{Towle2014,
abstract = {Service robots have the potential of improving the quality of life and assist with people's daily activities. Such robots must be capable of operating over long periods of time, performingmultiple tasks, and scheduling them appro- priately for execution. In addition, service robots must be capable of dealing with tasks whose goals may be in conflict with each other and would need to determine, dynamically, which task to pursue in such a case. Adding to the complex- ity of the problem is the fact that some task requests may have time constraints—deadlines by which the task has to be completed. Given the dynamic nature of the environment, the robots must make decisions on what tasks to pursue in situ- ations where there could be incomplete or missing informa- tion. The robots should also be capable of accepting requests for new tasks or services at runtime, while possibly working on another task. In order to achieve these requirements, this paper presents the Auction Behavior-Based Robotic Archi- tecture that brings the following contributions: (1) it uses an auction mechanism to determine the relevance of a task to run at any given time, (2) it handles multiple user requests while dealing with potentially critical time constraints and incom- plete information, (3) it enables long-term robot operation and (4) it allows for dynamic assignment of new tasks. The proposed system is validated on a physical robotic platform, the Segway RMP? and in simulation.},
author = {Towle, Bradford a. and Nicolescu, Monica},
doi = {10.1007/s11370-013-0141-7},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Towle, Nicolescu - 2014 - An auction behavior-based robotic architecture for service robotics.pdf:pdf},
isbn = {9781601321855},
issn = {18612784},
journal = {Intelligent Service Robotics},
keywords = {Auction-based robotic architecture,Behavior-based robotics,Dynamic time and environmental constraints,Intelligent action selection},
pages = {157--174},
title = {{An auction behavior-based robotic architecture for service robotics}},
volume = {7},
year = {2014}
}
@article{Nicolescu2008,
author = {Nicolescu, Monica and {Chadwicke Jenkins}, Odest and Olenderski, Adam and Fritzinger, Eric},
doi = {10.1075/is.9.2.09nic},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nicolescu et al. - 2008 - Learning behavior fusion from demonstration.pdf:pdf},
issn = {15720373},
journal = {Interaction Studies},
pages = {319--352},
title = {{Learning behavior fusion from demonstration}},
volume = {9},
year = {2008}
}
@article{Bicho2011,
abstract = {In this chapter we present results of our ongoing research on efficient and fluent human-robot collaboration that is heavily inspired by recent experimental findings about the neurocognitive mechanisms supporting joint action in humans. The robot control architecture implements the joint coordination of actions and goals as a dynamic process that integrates contextual cues, shared task knowledge and the predicted outcome of the user's motor behavior. The architecture is formalized as a coupled system of dynamic neural fields representing a distributed network of local but connected neural populations with specific functionalities. We validate the approach in a task in which a robot and a human user jointly construct a toy ‘vehicle'. We show that the context-dependent mapping from action observation onto appropriate complementary actions allows the robot to cope with dynamically changing joint action situations. More specifically, the results illustrate crucial cognitive capacities for efficient and successful human-robot collaboration such as goal inference, error detection and anticipatory action selection.},
author = {Bicho, Estela and Erlhagen, Wolfram and Louro, Lu{\'{i}}s and {Costa e Silva}, Eliana and Silva, Rui and Hip{\'{o}}lito, Nzoji},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bicho et al. - 2011 - A dynamic field approach to goal inference, error detection and anticipatory action selection in human-robot colla.pdf:pdf},
isbn = {978-9027204554},
journal = {New Frontiers in Human-Robot Interaction (Advances in Interaction Studies)},
keywords = {Action selection,Anticipation,Dynamic Fields,Error detection,Goal inference,Human-robot collaboration,Human-robot interaction},
pages = {135--164},
title = {{A dynamic field approach to goal inference, error detection and anticipatory action selection in human-robot collaboration}},
url = {http://benjamins.com/{\#}catalog/books/ais.2.10bic/details$\backslash$nhttp://hdl.handle.net/1822/17339},
year = {2011}
}
@article{Hayes,
author = {Hayes, Bradley and Scassellati, Brian},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hayes, Scassellati - Unknown - Discovering Task Constraints Through Observation and Active Learning.pdf:pdf},
title = {{Discovering Task Constraints Through Observation and Active Learning}}
}
@article{BarryBrianWerger,
author = {{Barry Brian Werger}, Maja J. Mataric},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barry Brian Werger - Unknown - Broadcast of Local Eligibility for Multi-Target Observation.pdf:pdf},
pages = {347----356},
title = {{Broadcast of Local Eligibility for Multi-Target Observation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.996}
}
@article{DeyuanQiu,
author = {{Deyuan Qiu Stefan May}, Andreas N{\"{u}}chter},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deyuan Qiu - Unknown - GPU-Accelerated nearest neighbor search for 3d registration.pdf:pdf},
title = {{GPU-Accelerated nearest neighbor search for 3d registration}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.323.7141}
}
@conference{288,
author = {Quigley, Morgan and Conley, Ken and Gerkey, Brian P and Faust, Josh and Foote, Tully and Leibs, Jeremy and Wheeler, Rob and Ng, Andrew Y},
booktitle = {ICRA Workshop on Open Source Software},
title = {{ROS: an open-source Robot Operating System}},
year = {2009}
}
@inproceedings{Koppula-RSS-13,
address = {Berlin, Germany},
author = {Koppula, Hema and Saxena, Ashutosh},
booktitle = {Proceedings of Robotics: Science and Systems},
month = {jun},
title = {{Anticipating Human Activities using Object Affordances for Reactive Robotic Response}},
year = {2013}
}
@inproceedings{Wong-RSS-14,
address = {Berkeley, USA},
author = {Wong, Kai Weng and Ehlers, R{\"{u}}diger and Kress-Gazit, Hadas},
booktitle = {Proceedings of Robotics: Science and Systems},
month = {jul},
title = {{Correct High-level Robot Behavior in Environments with Unexpected Events}},
year = {2014}
}
@inproceedings{erol1994umcp,
author = {Erol, Kutluhan and Hendler, James A and Nau, Dana S},
booktitle = {AIPS},
pages = {249--254},
title = {{UMCP: A Sound and Complete Procedure for Hierarchical Task-network Planning.}},
volume = {94},
year = {1994}
}
@inproceedings{erol1994htn,
author = {Erol, Kutluhan and Hendler, James and Nau, Dana S},
booktitle = {AAAI},
pages = {1123--1128},
title = {{HTN planning: Complexity and expressivity}},
volume = {94},
year = {1994}
}
@article{penberthy1992ucpop,
author = {Penberthy, J Scott and Weld, Daniel S and Others},
journal = {Kr},
pages = {103--114},
publisher = {Citeseer},
title = {{UCPOP: A Sound, Complete, Partial Order Planner for ADL.}},
volume = {92},
year = {1992}
}
@article{maes1989right,
author = {Maes, Pattie},
journal = {Connection Science},
number = {3},
pages = {291--323},
publisher = {Taylor {\&} Francis},
title = {{How to do the right thing}},
volume = {1},
year = {1989}
}
@book{arkin1998behavior,
author = {Arkin, Ronald C},
publisher = {MIT press},
title = {{Behavior-based robotics}},
year = {1998}
}
@inproceedings{BareaEtAl01,
address = {Helsinki, Finland},
author = {Barea, R and Boquete, L and Mazo, M and L{\~{A}}³pez, E and Bergasa, L M},
booktitle = {International Conference on Field and Service Robots},
month = {jun},
title = {{Electrooculgraphic guidance of a wheelchair using eye movements codification}},
year = {2001}
}
@inproceedings{PolotskiEtAl01,
address = {Helsinki, Finland},
author = {Polotski, V and Ahmadi, M and Cohen, P},
booktitle = {International Conference on Field and Service Robots},
month = {jun},
title = {{Localization and control of a tracked mining vehicle}},
year = {2001}
}
@inproceedings{SchollEtAl01,
address = {Helsinki, Finland},
author = {Scholl, K -U. and Kepplin, V and Berns, K and Dillmann, R},
booktitle = {International Conference on Field and Service Robots},
month = {jun},
title = {{Autonomous sewer inspection: Sensorbased navigation}},
year = {2001}
}
@inproceedings{KantorEtAl01,
address = {Helsinki, Finland},
author = {Kantor, G and Herman, H and Tabacchi, S Singh J and Kaufman, W},
booktitle = {International Conference on Field and Service Robots},
month = {jun},
title = {{Automatic railway classification using surface and subsurface measurements}},
year = {2001}
}
@inproceedings{UrmsonEtAl01,
address = {Helsinki, Finland},
author = {Urmson, C and Shamah, B and Teza, J and Wagner, M D and Apostolopoulos, D and Whittaker, William},
booktitle = {International Conference on Field and Service Robots},
month = {jun},
title = {{A sensor arm for robotic Antarctic meteorite search}},
year = {2001}
}
@inproceedings{WettergreenEtAl99,
address = {Pittsburgh, PA},
author = {Wettergreen, D and Gaskett, C and Zelinsky, A},
booktitle = {International Conference on Field and Service Robots},
month = {aug},
title = {{Autonomous Guidance and Control for an Underwater Robotic Vehicle}},
year = {1999}
}
@book{YuhEtAl96,
author = {Yuh, Junku and Ura, T and Bekey, George},
publisher = {Kluwer Press},
title = {{Underwater Robots}},
year = {1996}
}
@misc{CleaningContest,
author = {Contest, Cleaning},
month = {oct},
title = {{First International Cleaning Robot Contest, Lausanne, Switzerland}},
year = {2002}
}
@article{Nourbakshsh99,
author = {Nourbaksh, Illah},
journal = {Artificial Intelligence},
number = {1--2},
pages = {95--124},
title = {{An affective mobile robot educator with a full-time job}},
volume = {114},
year = {1999}
}
@article{KrebsEtAl00,
author = {Krebs, H and Volpe, B and Aisen, M and Hogan, N},
journal = {Journal of Rehabilitation Research and Development},
number = {6},
title = {{Increasing productivity and quality of care: robot-aided neurorehabilitation}},
volume = {37},
year = {2000}
}
@article{WilkesEtAl98,
author = {Wilkes, D and Alford, A and Pack, R and Rogers, T and Peters, R and Kawamura, K},
journal = {Applied Artificial Intelligence},
number = {7--8},
title = {{Toward socially intelligent service robots}},
volume = {12},
year = {1998}
}
@article{Murphy04,
author = {Murphy, Robin},
journal = {IEEE Systems, Man and Cybernetics Part C: Applications and Reviews, special issue on Human-Robot Interaction},
month = {may},
number = {2},
title = {{Human-Robot Interaction in Rescue Robotics}},
volume = {34},
year = {2004}
}
@article{AmbroseEtAl00,
author = {Ambrose, Robert and Aldridge, H and Burridge, R and Bluethman, W and Diftler, M and Lovchik, C and Magruder, D and Rehnmark, F},
journal = {IEEE Intelligent Systems Journal},
month = {aug},
title = {{ROBONAUT: NASA's Space Humanoid}},
year = {2000}
}
@inproceedings{NicolescuMataricAgents02,
address = {Bologna, Italy},
author = {Nicolescu, Monica N and Matari{\'{c}}, Maja J},
booktitle = {Proc., First Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems},
month = {jul},
pages = {227--233},
title = {{A Hierarchical Architecture for Behavior-Based Robots}},
year = {2002}
}
@inproceedings{NicolescuMataricAgents03,
address = {Melbourne, Australia},
author = {Nicolescu, Monica N and Matari{\'{c}}, Maja J},
booktitle = {Proc., Second Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems},
month = {jul},
title = {{Natural Methods for Robot Task Learning: Instructive Demonstration, Generalization and Practice}},
year = {2003}
}
@article{kalal2012tracking,
author = {Kalal, Zdenek and Mikolajczyk, Krystian and Matas, Jiri},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {7},
pages = {1409--1422},
publisher = {IEEE},
title = {{Tracking-learning-detection}},
volume = {34},
year = {2012}
}
@article{opencv_library,
author = {Bradski, G},
journal = {Dr. Dobb's Journal of Software Tools},
keywords = {bibtex-import},
title = {{No Title}},
year = {2000}
}
@article{ompl,
annote = {$\backslash$url{\{}http://ompl.kavrakilab.org{\}}},
author = {$\backslash$cSucan, Ioan A and Moll, Mark and Kavraki, Lydia E},
doi = {10.1109/MRA.2012.2205651},
journal = {{\{}IEEE{\}} Robotics {\&} Automation Magazine},
month = {dec},
number = {4},
pages = {72--82},
title = {{The {\{}O{\}}pen {\{}M{\}}otion {\{}P{\}}lanning {\{}L{\}}ibrary}},
volume = {19},
year = {2012}
}
@misc{Rocha2013,
abstract = {Skeltrack is a Free and Open Source Software library for tracking the human skeleton joints from depth images. It is implemented with GLib and uses plain mathematics to detect the human skeleton and although it does not use any database, it was inspired by Andreas Baak's paper: A Data-Driven Approach for Real-Time Full Body Pose Reconstruction from a Depth Camera},
author = {Rocha, Joaquim},
title = {{Skeltrack}},
url = {https://github.com/joaquimrocha/Skeltrack},
year = {2013}
}
@article{Montesano2008,
abstract = {Affordances encode relationships between actions, objects, and effects. They play an important role on basic cognitive capabilities such as prediction and planning. We address the problem of learning affordances through the interaction of a robot with the environment, a key step to understand the world properties and develop social skills. We present a general model for learning object affordances using Bayesian networks integrated within a general developmental architecture for social robots. Since learning is based on a probabilistic model, the approach is able to deal with uncertainty, redundancy, and irrelevant information. We demonstrate successful learning in the real world by having an humanoid robot interacting with objects. We illustrate the benefits of the acquired knowledge in imitation games.},
author = {Montesano, L. and Lopes, M. and Bernardino, a. and Santos-Victor, J.},
doi = {10.1109/TRO.2007.914848},
file = {:home/luke/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Montesano et al. - 2008 - Learning Object Affordances From Sensory--Motor Coordination to Imitation.pdf:pdf},
isbn = {1552-3098},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
keywords = {,Affordances,biorobotics,cognitive robotics,humanoid robots,learning},
number = {1},
pages = {15--26},
title = {{Learning Object Affordances: From Sensory--Motor Coordination to Imitation}},
volume = {24},
year = {2008}
}
@inproceedings{Ortega-Arranz2013,
abstract = {The single-source shortest path (SSSP) problem arises in many different fields. In this paper, we present a GPU SSSP algorithm implementation. Our work significantly speeds up the computation of the SSSP, not only with respect to a CPU-based version, but also to other state-of-the-art GPU implementations based on Dijkstra. Both GPU implementations have been evaluated using the latest NVIDIA architectures. The graphs chosen as input sets vary in nature, size, and fan-out degree, in order to evaluate the behavior of the algorithms for different data classes. Additionally, we have enhanced our GPU algorithm implementation using two optimization techniques: The use of a proper choice of threadblock size; and the modification of the GPU L1 cache memory state of NVIDIA devices. These optimizations lead to performance improvements of up to 23 {\%} with respect to the non-optimized versions. In addition, we have made a platform comparison of several NVIDIA boards in order to distinguish which one is better for each class of graphs, depending on their features. Finally, we compare our results with an optimized sequential implementation of Dijkstra's algorithm included in the reference Boost library, obtaining an improvement ratio of up to 19},
author = {Ortega-Arranz, Hector and Torres, Yuri and Gonzalez-Escribano, Arturo and Llanos, Diego R. and Gonzalez-Escribano, Arturo},
booktitle = {2013 International Conference on High Performance Computing {\&} Simulation (HPCS)},
doi = {10.1007/s10766-015-0351-z},
isbn = {978-1-4799-0838-7},
issn = {0885-7458},
keywords = {,Boost library,CPU-based version,Complexity theory,Computer architecture,Dijkstra,Dijkstra-based GPU implementation,Economics,GPGPU,GPU,GPU- based version,GPU-Crauser algorithm,GPU-Martin algorithm,GPU-based approach,Graphics processing units,Kepler,Kernel,Kernel characterization,NSSP,NVIDIA platform comparison,Nvidia architecture,Optimization techniques,Parallel Algorithms,Parallel processing,SSSP,SSSP problem,Vectors,graphics processing units,multiprocessing systems,parallel architectures,performance gain,shortest path problem,single-source shortest path problem},
language = {English},
month = {jul},
pages = {505--511},
publisher = {IEEE},
title = {{Comprehensive Evaluation of a New GPU-based Approach to the Shortest Path Problem}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6641461 http://link.springer.com/10.1007/s10766-015-0351-z},
year = {2013}
}
